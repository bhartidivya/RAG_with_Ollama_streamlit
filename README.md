# RAG_with_Ollama_streamlit
Retrieval-Augmented Generation Chat Bot using Ollama, Langchain and Streamlit.
![image](https://github.com/user-attachments/assets/924d3a62-c9ea-4773-ad2e-59a273ab687d)

### Running RAG with Ollama and streamlit

1. Install the required dependencies by running:

```bash
pip install -r requirements.txt
```
2. Install Ollama to run LLM models locally.
3. To invoke the downloaded LLM models locally
```bash
ollama pull mistral
ollama serve
```
4. For Q/A using streamit
```bash
streamlit run app.py
```



